{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1gafN4UvIUON7hMJzSRTGG1mIEhQC6B2R","timestamp":1739041126419}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","from google.colab import drive\n","#wait need the skin color metadata for smote\n","# Mount Google Drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I6o-NMGjMC1G","executionInfo":{"status":"ok","timestamp":1742599114889,"user_tz":420,"elapsed":32340,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}},"outputId":"a34d4b46-bb12-49b5-b718-b939e9dc3e2a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["Make DataLoader for the newdataset"],"metadata":{"id":"CHJCNynDS6Lg"}},{"cell_type":"code","source":["from torch.utils.data import Dataset,  DataLoader\n","import torchvision.transforms as transforms\n","import os\n","from PIL import Image\n","\n","class HAM100000(Dataset):\n","    def __init__(self, csv_file, part1_dir, part2_dir, transform):\n","      self.data = pd.read_csv(csv_file)[['image_id', 'dx']]\n","      self.part1_dir = part1_dir\n","      self.part2_dir = part2_dir\n","      self.transform = transform\n","      self.split_index = 29305\n","      self.label_map = {  # Convert labels to integers\n","            'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3,\n","            'mel': 4, 'nv': 5, 'vasc': 6\n","        }\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        img_filename = self.data.iloc[idx, 0]\n","        label = self.label_map[self.data.iloc[idx, 1]]\n","        fileSplit = int(self.data.iloc[idx, 0].split('_')[1])\n","        if fileSplit <= self.split_index:\n","          img_path = os.path.join(self.part1_dir, img_filename)+'.jpg'\n","        else:\n","          img_path = os.path.join(self.part2_dir, img_filename) +'.jpg'\n","        image = Image.open(img_path).convert(\"RGB\")\n","        if self.transform:\n","          image = self.transform(image)\n","\n","        return image, label"],"metadata":{"id":"VrS4oHPQS-ut","executionInfo":{"status":"ok","timestamp":1742599126803,"user_tz":420,"elapsed":11909,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Load ImageFolder\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor()\n","])\n","\n","path_1 = \"/content/drive/MyDrive/AJL Team 2/Ham10000/HAM10000_images_part_1\"\n","path_2 = \"/content/drive/MyDrive/AJL Team 2/Ham10000/HAM10000_images_part_2\"\n","csvpath = \"/content/drive/MyDrive/AJL Team 2/Ham10000/HAM10000_metadata.csv\"\n","\n","dataset_Ham10000 = HAM100000(csvpath, path_1, path_2, transform)"],"metadata":{"id":"9Tl4ah8JTUbb","executionInfo":{"status":"ok","timestamp":1742599141684,"user_tz":420,"elapsed":2927,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import random_split\n","#make dataloaders into train and validation split\n","train_size = int(0.8 * len(dataset_Ham10000))\n","val_size = len(dataset_Ham10000) - train_size\n","train_dataset_HAM10000, val_dataset_HAM10000 = random_split(dataset_Ham10000, [train_size, val_size])\n","\n"],"metadata":{"id":"jxyVNTClX2LQ","executionInfo":{"status":"ok","timestamp":1742599141687,"user_tz":420,"elapsed":1,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["#now want to create the ResNet50 that we are first going to train on the HAM dataset"],"metadata":{"id":"zLTqxdANYfOK"}},{"cell_type":"code","source":["#get device\n","import torch\n","import torch.nn as nn\n","from torchvision import models\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_zmSmvXuTTtX","executionInfo":{"status":"ok","timestamp":1742599144244,"user_tz":420,"elapsed":4,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}},"outputId":"9d26b067-e4a3-44ff-b4cb-73b075c13e2e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["!pip install torcheval"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gsFYouT-bbgN","executionInfo":{"status":"ok","timestamp":1742599148411,"user_tz":420,"elapsed":3123,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}},"outputId":"af9b0041-e831-4746-bd05-4ca843ec522a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torcheval\n","  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torcheval) (4.12.2)\n","Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torcheval\n","Successfully installed torcheval-0.0.7\n"]}]},{"cell_type":"code","source":["import torch\n","from torcheval.metrics import MulticlassAccuracy, MulticlassF1Score\n","from tqdm import tqdm\n","\n","# Function to train and validate model\n","def train_model(model, train_data, val_data, batch_size, criterion, optimizer, num_classes, device, save_path, num_epochs=10, scheduler = None):\n","\n","    # Create DataLoaders\n","\n","    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers = 2, pin_memory = True)\n","    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers = 2, pin_memory = True)\n","    model.to(device)\n","    best_val_loss = float('inf')\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        scaler = torch.amp.GradScaler(device)\n","\n","        for images, labels in tqdm(train_loader):\n","            images, labels = images.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            with torch.cuda.amp.autocast():\n","              outputs = model(images)\n","              loss = criterion(outputs, labels)\n","\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","\n","            running_loss += loss.item()\n","\n","        avg_train_loss = running_loss / len(train_loader)\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0.0\n","        accuracy_metric = MulticlassAccuracy(num_classes=num_classes, device = device)\n","        f1_metric = MulticlassF1Score(num_classes=num_classes, average=\"macro\", device = device)\n","\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","\n","                # Update metrics\n","                accuracy_metric.update(outputs, labels)\n","                f1_metric.update(outputs, labels)\n","\n","        avg_val_loss = val_loss / len(val_loader)\n","        val_accuracy = accuracy_metric.compute().item()\n","        val_f1 = f1_metric.compute().item()\n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n","\n","        # Save best model\n","        if avg_val_loss < best_val_loss:\n","            best_val_loss = avg_val_loss\n","            save_model(model, save_path)\n","\n","         # Step the scheduler if provided\n","        if scheduler:\n","            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n","                scheduler.step(avg_val_loss)  # ReduceLROnPlateau needs validation loss\n","            else:\n","                scheduler.step()  # Other schedulers just step normally\n","\n","# Function to save model\n","def save_model(model, path=\"/content/drive/MyDrive/AJL Team 2/HAM1000model.pth\"):\n","    torch.save(model.state_dict(), path)\n","    print(f\"Model saved to {path}\")\n"],"metadata":{"id":"NIVvFNyOYmyH","executionInfo":{"status":"ok","timestamp":1742599149810,"user_tz":420,"elapsed":1391,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Define the model"],"metadata":{"id":"5OReSWDKZ6DN"}},{"cell_type":"code","source":["#design the model\n","model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n","#need to change the fc to finetune it\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 7)  # 7 classes for HAM10000\n","\n","# Freeze all layers\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# Unfreeze `layer3 amd 4` and `fc`\n","for param in model.layer3.parameters():\n","    param.requires_grad = True\n","\n","for param in model.layer4.parameters():\n","    param.requires_grad = True\n","\n","for param in model.fc.parameters():\n","    param.requires_grad = True\n","\n","\n","# Move model to GPU\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aBvJdFSXZhcC","executionInfo":{"status":"ok","timestamp":1742584736088,"user_tz":420,"elapsed":3055,"user":{"displayName":"Ava Gonick","userId":"14093541435050724744"}},"outputId":"a1fcf931-91b0-4130-d114-dedaf66b9873","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n","100%|██████████| 97.8M/97.8M [00:01<00:00, 79.6MB/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=7, bias=True)\n",")"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["pretrain on ham10000"],"metadata":{"id":"at5z99dsZ7QD"}},{"cell_type":"code","source":["#probably needs a learning rate schedular to drop the learning rate\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","path = \"/content/drive/MyDrive/AJL Team 2/HAM1000model.pth\"\n","# Loss and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","#give it an optimizer\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","#give a learning rate schedular\n","scheduler = CosineAnnealingLR(optimizer, T_max=10)  # 10 epochs total\n","\n","train_model(model, train_dataset_HAM10000, val_dataset_HAM10000, 64, criterion, optimizer, 7, device, path, 10, scheduler)"],"metadata":{"id":"RxLqir1nZ_JV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742587905544,"user_tz":420,"elapsed":3169454,"user":{"displayName":"Ava Gonick","userId":"14093541435050724744"}},"outputId":"8765a571-a647-4a54-875b-03ba59a6b84f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/126 [00:00<?, ?it/s]<ipython-input-7-98d2e47b2ac6>:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n","100%|██████████| 126/126 [28:11<00:00, 13.43s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Train Loss: 0.8233, Val Loss: 0.6019, Val Acc: 0.7843, Val F1: 0.4005\n","Model saved to /content/drive/MyDrive/AJL Team 2/HAM1000model.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 126/126 [01:35<00:00,  1.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/10], Train Loss: 0.3840, Val Loss: 0.4982, Val Acc: 0.8288, Val F1: 0.6587\n","Model saved to /content/drive/MyDrive/AJL Team 2/HAM1000model.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 126/126 [01:32<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/10], Train Loss: 0.1393, Val Loss: 0.5098, Val Acc: 0.8502, Val F1: 0.7339\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 126/126 [01:29<00:00,  1.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/10], Train Loss: 0.0479, Val Loss: 0.5650, Val Acc: 0.8462, Val F1: 0.7464\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 126/126 [01:32<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/10], Train Loss: 0.0223, Val Loss: 0.6208, Val Acc: 0.8447, Val F1: 0.7401\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 126/126 [01:30<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/10], Train Loss: 0.0203, Val Loss: 0.5993, Val Acc: 0.8497, Val F1: 0.7468\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 126/126 [01:42<00:00,  1.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/10], Train Loss: 0.0094, Val Loss: 0.6168, Val Acc: 0.8547, Val F1: 0.7711\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 126/126 [01:33<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/10], Train Loss: 0.0058, Val Loss: 0.6225, Val Acc: 0.8577, Val F1: 0.7682\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 126/126 [01:33<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/10], Train Loss: 0.0059, Val Loss: 0.5998, Val Acc: 0.8577, Val F1: 0.7498\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 126/126 [01:30<00:00,  1.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/10], Train Loss: 0.0039, Val Loss: 0.6010, Val Acc: 0.8572, Val F1: 0.7617\n"]}]},{"cell_type":"markdown","source":["If needed to keep training the model that was made above load it in and keep training!"],"metadata":{"id":"4ZDImxoiAW9i"}},{"cell_type":"code","source":["#want to grab the saved model after this because want faster eval on cuda, havent used yet\n","# Define the model architecture (must match the saved model)\n","\n","#design the model\n","modelBest = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n","#need to change the fc to finetune it\n","num_ftrs = modelBest.fc.in_features\n","modelBest.fc = nn.Linear(num_ftrs, 7)  # 7 classes for HAM10000\n","\n","\n","# Load the saved weights\n","modelBest.load_state_dict(torch.load(\"/content/drive/MyDrive/AJL Team 2/HAM1000model.pth\", map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n","\n","# Freeze all layers\n","for param in modelBest.parameters():\n","    param.requires_grad = False\n","\n","# Unfreeze `layer3 amd 4` and `fc`\n","for param in modelBest.layer3.parameters():\n","    param.requires_grad = True\n","\n","for param in modelBest.layer4.parameters():\n","    param.requires_grad = True\n","\n","for param in modelBest.fc.parameters():\n","    param.requires_grad = True\n","\n","# Move model to GPU\n","model.to(device)\n"],"metadata":{"id":"j1G5vOk8_MuT","colab":{"base_uri":"https://localhost:8080/","height":227},"collapsed":true,"executionInfo":{"status":"error","timestamp":1742599161950,"user_tz":420,"elapsed":7932,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}},"outputId":"625d04ed-9f8a-4ca6-9117-c9b5e064a176"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 163MB/s]\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-68b480e936b8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Move model to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","source":["# Loss and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","#give it an optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","train_model(model, train_dataset_HAM10000, val_dataset_HAM10000, 64, criterion, optimizer, 7, device, 5)"],"metadata":{"id":"O0oT302nAcAR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now time to use the dataset we were given"],"metadata":{"id":"TIIt_kq1aNnG"}},{"cell_type":"code","source":["from torchvision.datasets import ImageFolder\n","class ImageFolderWithColor(Dataset):\n","    def __init__(self, image_folder):\n","        self.image_folder = image_folder\n","        self.image_paths, self.labels = zip(*self.image_folder.samples)\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        label = self.labels[idx]\n","        # Extract filename from the path\n","        filename = os.path.basename(img_path)\n","\n","        # Load image and apply transformations\n","        image, _ = self.image_folder[idx]\n","\n","        return image, label"],"metadata":{"id":"0jQHisC5MGf1","executionInfo":{"status":"ok","timestamp":1742599174737,"user_tz":420,"elapsed":45,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#add in a bunch of transforms\n","transform = transforms.Compose([transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(4/5, 5/4)),  # Keeps most of the lesion\n","    transforms.RandomHorizontalFlip(p=0.5),  # Flip images randomly\n","    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15),  # Preserve color, minimal hue change\n","    transforms.RandomRotation(degrees=10),  # Small rotations\n","    transforms.GaussianBlur(kernel_size=(3,3), sigma=(0.1, 0.5)),  # Slight blur\n","    transforms.ToTensor()  # Convert to tensor (NO NORMALIZATION, does not make sense for this task!)\n","])\n","\n","path = \"/content/drive/MyDrive/AJL Team 2/bttai-ajl-2025/balanced_augmented_dataset\"\n","# Load dataset from the correct directory\n","dataset_pre = ImageFolder(root=path, transform=transform)\n","\n","# Create the custom dataset\n","dataset = ImageFolderWithColor(dataset_pre)\n","\n","# Load into DataLoader\n","data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"],"metadata":{"id":"bWuhWm0FMHYE","executionInfo":{"status":"ok","timestamp":1742599183168,"user_tz":420,"elapsed":7065,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import random_split\n","# Split into training and validation sets\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"],"metadata":{"id":"rEc3Gx6CMJcY","executionInfo":{"status":"ok","timestamp":1742599183177,"user_tz":420,"elapsed":10,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#want to grab the saved model after this because want faster eval on cuda\n","# Define the model architecture (must match the saved model)\n","\n","#design the model\n","modelFinal = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n","#need to change the fc to finetune it\n","num_ftrs = modelFinal.fc.in_features\n","modelFinal.fc = nn.Linear(num_ftrs, 7)  # 21 classes in this dataset\n","\n","\n","# Load the saved weights\n","modelFinal.load_state_dict(torch.load(\"/content/drive/MyDrive/AJL Team 2/HAM1000model.pth\", map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n","\n","modelFinal.fc = nn.Linear(num_ftrs, 21) #switch out to correct size final layer\n","\n","# Freeze all layers\n","for param in modelFinal.parameters():\n","    param.requires_grad = False\n","\n","# Unfreeze `layer 4` and `fc`\n","\n","for param in modelFinal.layer4.parameters():\n","    param.requires_grad = True\n","\n","for param in modelFinal.fc.parameters():\n","    param.requires_grad = True\n","\n","# Move model to GPU\n","modelFinal.to(device)"],"metadata":{"id":"P5Eg6m9fcajm","executionInfo":{"status":"ok","timestamp":1742599184068,"user_tz":420,"elapsed":892,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f6faea4b-2573-459b-cc92-bea8265c122f"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=21, bias=True)\n",")"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["#now retrain the original model using the data we were given and see how it does\n","\n","#reduce lr if same for 2 epochs\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","#give it an optimizer, adding ab it of weight decay\n","optimizer = torch.optim.Adam(modelFinal.parameters(), lr=1e-4)\n","#use a learning rate schedular\n","\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n","#give a learning rate schedular\n","#scheduler = CosineAnnealingLR(optimizer, T_max=20)  # 10 epochs total\n","\n","# Loss and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","train_model(modelFinal, train_dataset, val_dataset, 64, criterion, optimizer , num_classes = 21, num_epochs=20, save_path = '/content/drive/MyDrive/AJL Team 2/resNet50_train_ham_first_20epochs_plateulr_patience_2_augmentedset',device=device, scheduler = scheduler)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mef0w7i9iVpU","outputId":"ed3d5139-b0d3-440a-c1ce-3645b2ea291a","executionInfo":{"status":"ok","timestamp":1742601342024,"user_tz":420,"elapsed":2157954,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/42 [00:00<?, ?it/s]<ipython-input-8-98d2e47b2ac6>:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n","100%|██████████| 42/42 [16:10<00:00, 23.12s/it]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/20], Train Loss: 2.1457, Val Loss: 1.7126, Val Acc: 0.3463, Val F1: 0.2417\n","Model saved to /content/drive/MyDrive/AJL Team 2/resNet50_train_ham_first_20epochs_plateulr_patience_2_augmentedset\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:38<00:00,  1.08it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/20], Train Loss: 1.4455, Val Loss: 1.4657, Val Acc: 0.4033, Val F1: 0.3409\n","Model saved to /content/drive/MyDrive/AJL Team 2/resNet50_train_ham_first_20epochs_plateulr_patience_2_augmentedset\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:39<00:00,  1.05it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/20], Train Loss: 1.2192, Val Loss: 1.3933, Val Acc: 0.4288, Val F1: 0.3726\n","Model saved to /content/drive/MyDrive/AJL Team 2/resNet50_train_ham_first_20epochs_plateulr_patience_2_augmentedset\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:39<00:00,  1.05it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/20], Train Loss: 1.0383, Val Loss: 1.4103, Val Acc: 0.4078, Val F1: 0.3720\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:37<00:00,  1.11it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/20], Train Loss: 0.8638, Val Loss: 1.3718, Val Acc: 0.4363, Val F1: 0.4009\n","Model saved to /content/drive/MyDrive/AJL Team 2/resNet50_train_ham_first_20epochs_plateulr_patience_2_augmentedset\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:39<00:00,  1.06it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/20], Train Loss: 0.6999, Val Loss: 1.4155, Val Acc: 0.4588, Val F1: 0.4272\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:36<00:00,  1.14it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/20], Train Loss: 0.5499, Val Loss: 1.4860, Val Acc: 0.4648, Val F1: 0.4116\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:39<00:00,  1.05it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/20], Train Loss: 0.4689, Val Loss: 1.5603, Val Acc: 0.4543, Val F1: 0.4432\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:37<00:00,  1.12it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/20], Train Loss: 0.3510, Val Loss: 1.5815, Val Acc: 0.4648, Val F1: 0.4438\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:39<00:00,  1.07it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/20], Train Loss: 0.3159, Val Loss: 1.5335, Val Acc: 0.4828, Val F1: 0.4664\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:38<00:00,  1.08it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [11/20], Train Loss: 0.2938, Val Loss: 1.6122, Val Acc: 0.4768, Val F1: 0.4399\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:38<00:00,  1.08it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [12/20], Train Loss: 0.2808, Val Loss: 1.5321, Val Acc: 0.4558, Val F1: 0.4480\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:39<00:00,  1.08it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [13/20], Train Loss: 0.2854, Val Loss: 1.5830, Val Acc: 0.4783, Val F1: 0.4705\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:37<00:00,  1.12it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [14/20], Train Loss: 0.2985, Val Loss: 1.5847, Val Acc: 0.4783, Val F1: 0.4671\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:39<00:00,  1.08it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [15/20], Train Loss: 0.2774, Val Loss: 1.6076, Val Acc: 0.4633, Val F1: 0.4425\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:37<00:00,  1.11it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [16/20], Train Loss: 0.2896, Val Loss: 1.5693, Val Acc: 0.4513, Val F1: 0.4274\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:39<00:00,  1.07it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [17/20], Train Loss: 0.2835, Val Loss: 1.5867, Val Acc: 0.4633, Val F1: 0.4386\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:38<00:00,  1.10it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [18/20], Train Loss: 0.2649, Val Loss: 1.5663, Val Acc: 0.4588, Val F1: 0.4365\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:38<00:00,  1.08it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [19/20], Train Loss: 0.2786, Val Loss: 1.5894, Val Acc: 0.4633, Val F1: 0.4426\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 42/42 [00:39<00:00,  1.07it/s]\n","WARNING:root:Warning: Some classes do not exist in the target. F1 scores for these classes will be cast to zeros.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [20/20], Train Loss: 0.2792, Val Loss: 1.5339, Val Acc: 0.4768, Val F1: 0.4519\n"]}]},{"cell_type":"code","source":["TestModel =  models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n","#need to change the fc to finetune it\n","num_ftrs = TestModel.fc.in_features\n","TestModel.fc = nn.Linear(num_ftrs, 21)  # 7 classes for HAM10000\n","\n","# Load the saved weights\n","TestModel.load_state_dict(torch.load(\"/content/drive/MyDrive/AJL Team 2/resNet50_train_ham_first_20epochs_plateulr_patience_2_augmentedset\", map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n","TestModel.to(device)"],"metadata":{"id":"Y7n1HyU2IpXM","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742601342887,"user_tz":420,"elapsed":850,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}},"outputId":"af71771d-14c7-4b77-b935-6c65cd36f75d"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=21, bias=True)\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["Get stuff for submitting a test file"],"metadata":{"id":"1hS-kAmucYYv"}},{"cell_type":"code","source":["#now need to get testing labels to submit\n","class TestDataset(torch.utils.data.Dataset):\n","    def __init__(self, csv_path, root_dir, transform=None):\n","        self.data = pd.read_csv(csv_path)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        row = self.data.iloc[idx]\n","        img_hash = row[\"md5hash\"]\n","\n","        img_path = os.path.join(self.root_dir, img_hash + \".jpg\")\n","\n","        if not os.path.exists(img_path):\n","            raise FileNotFoundError(f\"Image {img_hash}.jpg not found in {img_path}\")\n","\n","        image = Image.open(img_path).convert(\"RGB\")\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, img_hash  # return hash to map it to a label in submission csv\n","\n","# same transformations as training\n","test_transforms = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","path_test = '/content/drive/MyDrive/AJL Team 2/bttai-ajl-2025'\n","\n","# path to test CSV and test image folder\n","test_csv_path = os.path.join(path_test, 'test.csv')\n","test_root_dir = os.path.join(path_test, 'test', 'test')\n","\n","# load test dataset\n","test_dataset = TestDataset(test_csv_path, test_root_dir, transform=test_transforms)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n","\n","print(f\"Total test samples: {len(test_dataset)}\")"],"metadata":{"id":"4lnrzHXwXOyJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742601343835,"user_tz":420,"elapsed":946,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}},"outputId":"037a31a0-e598-43c8-a3b9-344d558ce17d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Total test samples: 1227\n"]}]},{"cell_type":"code","source":["def predict_and_save(model, test_loader, device, idx_to_class):\n","    model.eval\n","\n","    predictions = []\n","\n","    with torch.no_grad():\n","        for images, img_hashes in tqdm(test_loader, desc=\"Generating Predictions\"):\n","            images = images.to(device)\n","\n","            # predict\n","            outputs = model(images)\n","\n","            # Get predicted class index\n","            _, predicted = torch.max(outputs, 1)\n","\n","            # Convert index to class label\n","            predicted_labels = [idx_to_class[idx.item()] for idx in predicted]\n","\n","            # Store results\n","            for img_hash, label, in zip(img_hashes, predicted_labels):\n","                predictions.append({\"md5hash\": img_hash, \"label\": label})\n","    submission_df = pd.DataFrame(predictions)\n","    return submission_df"],"metadata":{"id":"ePiqM_P0fnN7","executionInfo":{"status":"ok","timestamp":1742601343840,"user_tz":420,"elapsed":3,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["\n","# Map indices to class labels\n","idx_to_class = {idx: cls for cls, idx in dataset_pre.class_to_idx.items()}\n","\n","# Run predictions and save\n","submission_df=predict_and_save(TestModel, test_loader, device, idx_to_class)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sl3rYTL3gZSr","executionInfo":{"status":"ok","timestamp":1742601909593,"user_tz":420,"elapsed":350561,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}},"outputId":"29307d9c-6331-486c-995c-474abb90904a"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["Generating Predictions: 100%|██████████| 77/77 [05:50<00:00,  4.55s/it]\n"]}]},{"cell_type":"code","source":["submission_df.head()\n","#Save to CSV\n","submission_df.to_csv(path_test + \"/ResNet50PreTrainOnHamInLoaderAugmentNoWeightDecayPatience2AugemntedSet.csv\", index=False)"],"metadata":{"id":"Aj3Urx6xgfAG","executionInfo":{"status":"ok","timestamp":1742601909631,"user_tz":420,"elapsed":7,"user":{"displayName":"UCLA CFC","userId":"14765659743041953666"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Naa9xxYuJIIg"},"execution_count":null,"outputs":[]}]}